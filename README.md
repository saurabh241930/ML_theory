# ML_theory

In a machine learning problem where the input is denoted by ğ± and the output is ğ‘¦

In order to do machine learning, there should exist a relationship (pattern) between the input and output values. Lets say that this the function
ğ‘¦=ğ‘“(ğ±), this known as the target function.

However, ğ‘“(.) is unknown function to us.  so machine learning algorithms try to guess a **hypothesis** function â„(ğ±) that approximates the unknown ğ‘“(.), the set of all possible hypotheses is known as the Hypothesis set ğ»(.), the goal is the learning process is to find the final hypothesis that best approximates the unknown target function.

Different machine learning models have different hypothesis sets, For example the 2d- perceptron has the hypothesis set
ğ»(ğ±)={ğ‘ ğ‘–ğ‘”ğ‘›(ğ‘¤1âˆ—ğ‘¥1+ğ‘¤2âˆ—ğ‘¥2+ğ‘¤0)âˆ€ğ‘¤0,ğ‘¤1,ğ‘¤2}

The following slide, Courtesy of Prof. Yasser Abu Moustafa Caltech, shows that relationships.
<img src = "https://qph.fs.quoracdn.net/main-qimg-cf260851f899a89ff16a92b38e73729f"/>

